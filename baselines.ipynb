{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO2PZhuLezmWMWKYOfW9TtI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/starryesh22/Test_Colab/blob/main/baselines.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7tSX1vlg9IKS"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import os\n",
        "import warnings\n",
        "\n",
        "from lightgbm import LGBMClassifier\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import f1_score\n",
        "from tqdm import tqdm\n",
        "import wfdb\n",
        "\n",
        "from utils import split_data, find_optimal_threshold\n",
        "from expert_features import extract_features\n",
        "\n",
        "warnings.filterwarnings('ignore', category=FutureWarning)\n",
        "\n",
        "\n",
        "def parse_args():\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('--data-dir', type=str, default='data/CPSC', help='Data directory')\n",
        "    parser.add_argument('--classifier', type=str, default='all', help='Classifier to use: LR, RF, LGB, or MLP')\n",
        "    parser.add_argument('--seed', type=int, default=42, help='Seed to split data')\n",
        "    return parser.parse_args()\n",
        "\n",
        "\n",
        "def generate_features_csv(features_csv, data_dir, patient_ids):\n",
        "    print('Generating expert features...')\n",
        "    ecg_features = []\n",
        "    for patient_id in tqdm(patient_ids):\n",
        "        ecg_data, _ = wfdb.rdsamp(os.path.join(data_dir, patient_id))\n",
        "        ecg_features.append(extract_features(ecg_data))\n",
        "    df = pd.DataFrame(ecg_features, index=patient_ids)\n",
        "    df.index.name = 'patient_id'\n",
        "    df.to_csv(features_csv)\n",
        "    return df\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    classes = ['SNR', 'AF', 'IAVB', 'LBBB', 'RBBB', 'PAC', 'PVC', 'STD', 'STE']\n",
        "    args = parse_args()\n",
        "    data_dir = args.data_dir\n",
        "    classifier = args.classifier\n",
        "    features_csv = os.path.join(data_dir, 'features.csv')\n",
        "    labels_csv = os.path.join(data_dir, 'labels.csv')\n",
        "\n",
        "    df_labels = pd.read_csv(labels_csv)\n",
        "    patient_ids = df_labels['patient_id'].tolist()\n",
        "    if not os.path.exists(features_csv):\n",
        "        df_X = generate_features_csv(features_csv, data_dir, patient_ids)\n",
        "    else:\n",
        "        df_X = pd.read_csv(features_csv)\n",
        "    df_X = df_X.merge(df_labels[['patient_id', 'fold']], on='patient_id')\n",
        "    \n",
        "    train_folds, val_folds, test_folds = split_data(seed=args.seed)\n",
        "    feature_cols = df_X.columns[1:-1] # remove patient id and fold\n",
        "\n",
        "    X_train = df_X[df_X['fold'].isin(train_folds)][feature_cols].to_numpy()\n",
        "    X_val = df_X[df_X['fold'].isin(val_folds)][feature_cols].to_numpy()\n",
        "    X_test = df_X[df_X['fold'].isin(test_folds)][feature_cols].to_numpy()\n",
        "\n",
        "    y_train = df_labels[df_labels['fold'].isin(train_folds)][classes].to_numpy()\n",
        "    y_val = df_labels[df_labels['fold'].isin(val_folds)][classes].to_numpy()\n",
        "    y_test = df_labels[df_labels['fold'].isin(test_folds)][classes].to_numpy()\n",
        "\n",
        "    if classifier == 'all':\n",
        "        classifiers = ['LR', 'RF', 'LGB', 'MLP']\n",
        "    else:\n",
        "        classifiers = [classifier]\n",
        "\n",
        "    for classifier in classifiers:\n",
        "        # tune parameters\n",
        "        if classifier == 'LR':\n",
        "            model = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
        "        elif classifier == 'RF':\n",
        "            model = RandomForestClassifier(n_estimators=300, max_depth=10)\n",
        "        elif classifier == 'LGB':\n",
        "            model = LGBMClassifier(n_estimators=100)\n",
        "        else:\n",
        "            model = MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=500)\n",
        "        if classifier != 'MLP':\n",
        "            model = OneVsRestClassifier(model)\n",
        "\n",
        "        print(f'Start training {classifier}...')\n",
        "        model.fit(X_train, y_train)\n",
        "        \n",
        "        y_val_scores = model.predict_proba(X_val)\n",
        "        y_test_scores = model.predict_proba(X_test)\n",
        "        \n",
        "        f1s = []\n",
        "        thresholds = []\n",
        "        print('Finding optimal thresholds on validation dataset...')\n",
        "\n",
        "        for i in range(len(classes)):\n",
        "            # find optimal threshold on validation dataset\n",
        "            y_val_score = y_val_scores[:, i]\n",
        "            threshold = find_optimal_threshold(y_val[:, i], y_val_score)\n",
        "            # apply optimal threshold to test dataset\n",
        "            y_test_score = y_test_scores[:, i]\n",
        "            y_test_pred = y_test_score > threshold\n",
        "            f1 = f1_score(y_test[:, i], y_test_pred)\n",
        "            thresholds.append(threshold)\n",
        "            f1s.append(f1)\n",
        "        np.set_printoptions(precision=3)\n",
        "        print(f'{classifier} F1s:', f1s)\n",
        "        print('Avg F1:', np.mean(f1s))\n"
      ]
    }
  ]
}